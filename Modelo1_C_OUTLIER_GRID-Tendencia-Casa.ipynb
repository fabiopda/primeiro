{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import ensemble\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = pd.read_csv('C:/Users/fabiopda/Desktop/MBA/Projeto Final/Original.csv')\n",
    "Base = Base.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de novas variáveis - Apostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = []\n",
    "for linha in range(0,len(Base)):\n",
    "    if Base['B365H'][linha] == Base['B365A'][linha]:\n",
    "        resultado.append(0)\n",
    "    else:\n",
    "        resultado.append(Base['B365H'][linha]/Base['B365A'][linha])\n",
    "Base['B365F'] = resultado\n",
    "\n",
    "resultado = []\n",
    "for linha in range(0,len(Base)):\n",
    "    if Base['BWH'][linha] == Base['BWA'][linha]:\n",
    "        resultado.append(0)\n",
    "    else:\n",
    "        resultado.append(Base['BWH'][linha]/Base['BWA'][linha])\n",
    "Base['BWF'] = resultado\n",
    "\n",
    "resultado = []\n",
    "for linha in range(0,len(Base)):\n",
    "    if Base['IWH'][linha] == Base['IWA'][linha]:\n",
    "        resultado.append(0)\n",
    "    else:\n",
    "        resultado.append(Base['IWH'][linha]/Base['IWA'][linha])\n",
    "Base['IWF'] = resultado\n",
    "\n",
    "resultado = []\n",
    "for linha in range(0,len(Base)):\n",
    "    if Base['LBH'][linha] == Base['LBA'][linha]:\n",
    "        resultado.append(0)\n",
    "    else:\n",
    "        resultado.append(Base['LBH'][linha]/Base['LBA'][linha])\n",
    "Base['LBF'] = resultado\n",
    "\n",
    "resultado = []\n",
    "for linha in range(0,len(Base)):\n",
    "    if Base['WHH'][linha] == Base['WHA'][linha]:\n",
    "        resultado.append(0)\n",
    "    else:\n",
    "        resultado.append(Base['WHH'][linha]/Base['WHA'][linha])\n",
    "Base['WHF'] = resultado\n",
    "\n",
    "resultado = []\n",
    "for linha in range(0,len(Base)):\n",
    "    if Base['VCH'][linha] == Base['VCA'][linha]:\n",
    "        resultado.append(0)\n",
    "    else:\n",
    "        resultado.append(Base['VCH'][linha]/Base['VCA'][linha])\n",
    "Base['VCF'] = resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação da variável resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultado = []\n",
    "\n",
    "for linha in range(0,len(Base)):\n",
    "    if Base['home_team_goal'][linha] > Base['away_team_goal'][linha]:\n",
    "        resultado.append(1)\n",
    "    elif Base['home_team_goal'][linha] == Base['away_team_goal'][linha]:\n",
    "        resultado.append(0)\n",
    "    else:\n",
    "        resultado.append(0)\n",
    "Base['Resultado_Casa'] = resultado\n",
    "\n",
    "Base = Base.drop(['home_team_goal','away_team_goal'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação da base de modelagem e de aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base_Aplicacao = Base.query(\"Ano_2016 > 0\")\n",
    "Base = Base.query(\"Ano_2016 == 0\")\n",
    "Base = Base.drop(['Ano_2009','Ano_2010','Ano_2011','Ano_2012','Ano_2013','Ano_2014','Ano_2015','Ano_2016'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação da base de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Base.drop(['Resultado_Casa'], axis=1)\n",
    "y = Base.Resultado_Casa\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "# Now apply the transformations to the data:\n",
    "X_train2 = scaler.transform(X_train)\n",
    "X_test2 = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.0001, 0.001, 0.002], 'max_iter': [15, 25, 50], 'random_state': [42]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.0001,0.001,0.002],'max_iter':[15,25,50],'random_state':[42]}]\n",
    "clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=3, scoring='accuracy')\n",
    "clf.fit(X_train2, y_train)\n",
    "\n",
    "#tuned_parameters = [{'C': [0.01,0.1,1],'max_iter':[100,200,1000],'random_state':[42]}]\n",
    "#{'C': 0.01, 'max_iter': 100, 'random_state': 42}\n",
    "#Accuracy: 0.5741\n",
    "#AUC: 0.5000\n",
    "\n",
    "#tuned_parameters = [{'C': [0.001,0.01,0.05],'max_iter':[50,100,150],'random_state':[42]}]\n",
    "#{'C': 0.001, 'max_iter': 50, 'random_state': 42}\n",
    "#Accuracy: 0.6000\n",
    "#AUC: 0.5915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.0001, 'max_iter': 15, 'random_state': 42}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.624 (+/-0.011) for {'C': 0.0001, 'max_iter': 15, 'random_state': 42}\n",
      "0.624 (+/-0.011) for {'C': 0.0001, 'max_iter': 25, 'random_state': 42}\n",
      "0.624 (+/-0.011) for {'C': 0.0001, 'max_iter': 50, 'random_state': 42}\n",
      "0.623 (+/-0.025) for {'C': 0.001, 'max_iter': 15, 'random_state': 42}\n",
      "0.623 (+/-0.025) for {'C': 0.001, 'max_iter': 25, 'random_state': 42}\n",
      "0.623 (+/-0.025) for {'C': 0.001, 'max_iter': 50, 'random_state': 42}\n",
      "0.616 (+/-0.009) for {'C': 0.002, 'max_iter': 15, 'random_state': 42}\n",
      "0.616 (+/-0.009) for {'C': 0.002, 'max_iter': 25, 'random_state': 42}\n",
      "0.616 (+/-0.009) for {'C': 0.002, 'max_iter': 50, 'random_state': 42}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "Accuracy: 0.6112\n",
      "\n",
      "AUC: 0.6259\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, clf.predict(X_test2))\n",
    "print(\"Accuracy: %.4f\" % acc)\n",
    "print()\n",
    "\n",
    "probs = clf.predict_proba(X_test)\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'max_depth': [2, 3, 7, 10], 'min_samples_split': [2, 3, 5, 10], 'criterion': ['gini', 'entropy'], 'random_state': [42]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = [{'max_depth': [2,3,7,10],\n",
    "                     'min_samples_split': [2,3,5,10],\n",
    "                     'criterion': ['gini','entropy'],\n",
    "                     'random_state':[42]}]\n",
    "\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), tuned_parameters, cv=3, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#tuned_parameters = [{'max_depth': [2,3,5],'min_samples_split': [1,2,3,4,7],'criterion': ['gini','entropy'],'random_state':[42]}]\n",
    "#{'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2, 'random_state': 42}\n",
    "#Accuracy: 0.6231\n",
    "#AUC: 0.6559\n",
    "\n",
    "#tuned_parameters = [{'max_depth': [2,3,7,10],'min_samples_split': [2,3,5,10],'criterion': ['gini','entropy'],'random_state':[42]}]\n",
    "#{'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2, 'random_state': 42}\n",
    "#Accuracy: 0.6231\n",
    "#AUC: 0.6559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2, 'random_state': 42}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.626 (+/-0.015) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2, 'random_state': 42}\n",
      "0.626 (+/-0.015) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 3, 'random_state': 42}\n",
      "0.626 (+/-0.015) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5, 'random_state': 42}\n",
      "0.626 (+/-0.015) for {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 10, 'random_state': 42}\n",
      "0.606 (+/-0.005) for {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'random_state': 42}\n",
      "0.606 (+/-0.005) for {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 3, 'random_state': 42}\n",
      "0.606 (+/-0.005) for {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 5, 'random_state': 42}\n",
      "0.606 (+/-0.005) for {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'random_state': 42}\n",
      "0.580 (+/-0.016) for {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 2, 'random_state': 42}\n",
      "0.580 (+/-0.016) for {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 3, 'random_state': 42}\n",
      "0.576 (+/-0.018) for {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 5, 'random_state': 42}\n",
      "0.578 (+/-0.022) for {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 10, 'random_state': 42}\n",
      "0.568 (+/-0.032) for {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'random_state': 42}\n",
      "0.568 (+/-0.032) for {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 3, 'random_state': 42}\n",
      "0.574 (+/-0.018) for {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'random_state': 42}\n",
      "0.562 (+/-0.001) for {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'random_state': 42}\n",
      "0.628 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2, 'random_state': 42}\n",
      "0.628 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 3, 'random_state': 42}\n",
      "0.628 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5, 'random_state': 42}\n",
      "0.628 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 10, 'random_state': 42}\n",
      "0.623 (+/-0.019) for {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'random_state': 42}\n",
      "0.623 (+/-0.019) for {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 3, 'random_state': 42}\n",
      "0.623 (+/-0.019) for {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'random_state': 42}\n",
      "0.623 (+/-0.019) for {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 10, 'random_state': 42}\n",
      "0.575 (+/-0.046) for {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 2, 'random_state': 42}\n",
      "0.575 (+/-0.046) for {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 3, 'random_state': 42}\n",
      "0.575 (+/-0.046) for {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 5, 'random_state': 42}\n",
      "0.569 (+/-0.059) for {'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 10, 'random_state': 42}\n",
      "0.558 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'random_state': 42}\n",
      "0.558 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 3, 'random_state': 42}\n",
      "0.562 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5, 'random_state': 42}\n",
      "0.559 (+/-0.027) for {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'random_state': 42}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "Accuracy: 0.6065\n",
      "\n",
      "AUC: 0.6363\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "print(\"Accuracy: %.4f\" % acc)\n",
    "print()\n",
    "\n",
    "probs = clf.predict_proba(X_test)\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [100, 200, 225], 'max_depth': [15, 17, 19], 'criterion': ['gini', 'entropy'], 'random_state': [42], 'max_features': [45, 50, 55]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = [{'n_estimators': [100,200,225],\n",
    "                     'max_depth': [15,17,19],\n",
    "                     'criterion':['gini','entropy'],\n",
    "                     'random_state':[42],\n",
    "                     'max_features': [45,50,55]}]\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=3, scoring='accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#tuned_parameters = [{'n_estimators': [100,250,300],\n",
    "#                     'max_depth': [1,3,5,15,20,25,50],\n",
    "#                     'criterion':['gini','entropy'],\n",
    "#                     'random_state':[42],\n",
    "#                     'max_features': [25,50,100,1146]}]\n",
    "\n",
    "#{'criterion': 'gini', 'max_depth': 20, 'max_features': 50, 'n_estimators': 250, 'random_state': 42}\n",
    "#Accuracy: 0.6027\n",
    "#AUC: 0.6443\n",
    "\n",
    "#tuned_parameters = [{'n_estimators': [200,250,275],\n",
    "#                     'max_depth': [19,20,21],\n",
    "#                     'criterion':['gini','entropy'],\n",
    "#                     'random_state':[42],\n",
    "#                     'max_features': [40,50,60]}]\n",
    "\n",
    "#{'criterion': 'gini', 'max_depth': 19, 'max_features': 50, 'n_estimators': 200, 'random_state': 42}\n",
    "#Accuracy: 0.5891\n",
    "#AUC: 0.6422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'criterion': 'gini', 'max_depth': 15, 'max_features': 55, 'n_estimators': 200, 'random_state': 42}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.642 (+/-0.017) for {'criterion': 'gini', 'max_depth': 15, 'max_features': 45, 'n_estimators': 100, 'random_state': 42}\n",
      "0.637 (+/-0.031) for {'criterion': 'gini', 'max_depth': 15, 'max_features': 45, 'n_estimators': 200, 'random_state': 42}\n",
      "0.640 (+/-0.031) for {'criterion': 'gini', 'max_depth': 15, 'max_features': 45, 'n_estimators': 225, 'random_state': 42}\n",
      "0.632 (+/-0.015) for {'criterion': 'gini', 'max_depth': 15, 'max_features': 50, 'n_estimators': 100, 'random_state': 42}\n",
      "0.642 (+/-0.028) for {'criterion': 'gini', 'max_depth': 15, 'max_features': 50, 'n_estimators': 200, 'random_state': 42}\n",
      "0.635 (+/-0.034) for {'criterion': 'gini', 'max_depth': 15, 'max_features': 50, 'n_estimators': 225, 'random_state': 42}\n",
      "0.638 (+/-0.012) for {'criterion': 'gini', 'max_depth': 15, 'max_features': 55, 'n_estimators': 100, 'random_state': 42}\n",
      "0.654 (+/-0.018) for {'criterion': 'gini', 'max_depth': 15, 'max_features': 55, 'n_estimators': 200, 'random_state': 42}\n",
      "0.652 (+/-0.010) for {'criterion': 'gini', 'max_depth': 15, 'max_features': 55, 'n_estimators': 225, 'random_state': 42}\n",
      "0.641 (+/-0.025) for {'criterion': 'gini', 'max_depth': 17, 'max_features': 45, 'n_estimators': 100, 'random_state': 42}\n",
      "0.637 (+/-0.033) for {'criterion': 'gini', 'max_depth': 17, 'max_features': 45, 'n_estimators': 200, 'random_state': 42}\n",
      "0.642 (+/-0.031) for {'criterion': 'gini', 'max_depth': 17, 'max_features': 45, 'n_estimators': 225, 'random_state': 42}\n",
      "0.632 (+/-0.022) for {'criterion': 'gini', 'max_depth': 17, 'max_features': 50, 'n_estimators': 100, 'random_state': 42}\n",
      "0.638 (+/-0.032) for {'criterion': 'gini', 'max_depth': 17, 'max_features': 50, 'n_estimators': 200, 'random_state': 42}\n",
      "0.638 (+/-0.025) for {'criterion': 'gini', 'max_depth': 17, 'max_features': 50, 'n_estimators': 225, 'random_state': 42}\n",
      "0.638 (+/-0.020) for {'criterion': 'gini', 'max_depth': 17, 'max_features': 55, 'n_estimators': 100, 'random_state': 42}\n",
      "0.644 (+/-0.017) for {'criterion': 'gini', 'max_depth': 17, 'max_features': 55, 'n_estimators': 200, 'random_state': 42}\n",
      "0.646 (+/-0.015) for {'criterion': 'gini', 'max_depth': 17, 'max_features': 55, 'n_estimators': 225, 'random_state': 42}\n",
      "0.644 (+/-0.014) for {'criterion': 'gini', 'max_depth': 19, 'max_features': 45, 'n_estimators': 100, 'random_state': 42}\n",
      "0.636 (+/-0.015) for {'criterion': 'gini', 'max_depth': 19, 'max_features': 45, 'n_estimators': 200, 'random_state': 42}\n",
      "0.647 (+/-0.018) for {'criterion': 'gini', 'max_depth': 19, 'max_features': 45, 'n_estimators': 225, 'random_state': 42}\n",
      "0.632 (+/-0.025) for {'criterion': 'gini', 'max_depth': 19, 'max_features': 50, 'n_estimators': 100, 'random_state': 42}\n",
      "0.634 (+/-0.037) for {'criterion': 'gini', 'max_depth': 19, 'max_features': 50, 'n_estimators': 200, 'random_state': 42}\n",
      "0.639 (+/-0.025) for {'criterion': 'gini', 'max_depth': 19, 'max_features': 50, 'n_estimators': 225, 'random_state': 42}\n",
      "0.642 (+/-0.010) for {'criterion': 'gini', 'max_depth': 19, 'max_features': 55, 'n_estimators': 100, 'random_state': 42}\n",
      "0.644 (+/-0.011) for {'criterion': 'gini', 'max_depth': 19, 'max_features': 55, 'n_estimators': 200, 'random_state': 42}\n",
      "0.646 (+/-0.012) for {'criterion': 'gini', 'max_depth': 19, 'max_features': 55, 'n_estimators': 225, 'random_state': 42}\n",
      "0.638 (+/-0.030) for {'criterion': 'entropy', 'max_depth': 15, 'max_features': 45, 'n_estimators': 100, 'random_state': 42}\n",
      "0.644 (+/-0.039) for {'criterion': 'entropy', 'max_depth': 15, 'max_features': 45, 'n_estimators': 200, 'random_state': 42}\n",
      "0.645 (+/-0.044) for {'criterion': 'entropy', 'max_depth': 15, 'max_features': 45, 'n_estimators': 225, 'random_state': 42}\n",
      "0.640 (+/-0.054) for {'criterion': 'entropy', 'max_depth': 15, 'max_features': 50, 'n_estimators': 100, 'random_state': 42}\n",
      "0.642 (+/-0.024) for {'criterion': 'entropy', 'max_depth': 15, 'max_features': 50, 'n_estimators': 200, 'random_state': 42}\n",
      "0.643 (+/-0.020) for {'criterion': 'entropy', 'max_depth': 15, 'max_features': 50, 'n_estimators': 225, 'random_state': 42}\n",
      "0.640 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 15, 'max_features': 55, 'n_estimators': 100, 'random_state': 42}\n",
      "0.638 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 15, 'max_features': 55, 'n_estimators': 200, 'random_state': 42}\n",
      "0.640 (+/-0.024) for {'criterion': 'entropy', 'max_depth': 15, 'max_features': 55, 'n_estimators': 225, 'random_state': 42}\n",
      "0.640 (+/-0.030) for {'criterion': 'entropy', 'max_depth': 17, 'max_features': 45, 'n_estimators': 100, 'random_state': 42}\n",
      "0.645 (+/-0.050) for {'criterion': 'entropy', 'max_depth': 17, 'max_features': 45, 'n_estimators': 200, 'random_state': 42}\n",
      "0.642 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 17, 'max_features': 45, 'n_estimators': 225, 'random_state': 42}\n",
      "0.628 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 17, 'max_features': 50, 'n_estimators': 100, 'random_state': 42}\n",
      "0.634 (+/-0.029) for {'criterion': 'entropy', 'max_depth': 17, 'max_features': 50, 'n_estimators': 200, 'random_state': 42}\n",
      "0.632 (+/-0.034) for {'criterion': 'entropy', 'max_depth': 17, 'max_features': 50, 'n_estimators': 225, 'random_state': 42}\n",
      "0.640 (+/-0.016) for {'criterion': 'entropy', 'max_depth': 17, 'max_features': 55, 'n_estimators': 100, 'random_state': 42}\n",
      "0.640 (+/-0.028) for {'criterion': 'entropy', 'max_depth': 17, 'max_features': 55, 'n_estimators': 200, 'random_state': 42}\n",
      "0.640 (+/-0.030) for {'criterion': 'entropy', 'max_depth': 17, 'max_features': 55, 'n_estimators': 225, 'random_state': 42}\n",
      "0.634 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 19, 'max_features': 45, 'n_estimators': 100, 'random_state': 42}\n",
      "0.639 (+/-0.041) for {'criterion': 'entropy', 'max_depth': 19, 'max_features': 45, 'n_estimators': 200, 'random_state': 42}\n",
      "0.635 (+/-0.038) for {'criterion': 'entropy', 'max_depth': 19, 'max_features': 45, 'n_estimators': 225, 'random_state': 42}\n",
      "0.643 (+/-0.044) for {'criterion': 'entropy', 'max_depth': 19, 'max_features': 50, 'n_estimators': 100, 'random_state': 42}\n",
      "0.634 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 19, 'max_features': 50, 'n_estimators': 200, 'random_state': 42}\n",
      "0.634 (+/-0.037) for {'criterion': 'entropy', 'max_depth': 19, 'max_features': 50, 'n_estimators': 225, 'random_state': 42}\n",
      "0.644 (+/-0.009) for {'criterion': 'entropy', 'max_depth': 19, 'max_features': 55, 'n_estimators': 100, 'random_state': 42}\n",
      "0.640 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 19, 'max_features': 55, 'n_estimators': 200, 'random_state': 42}\n",
      "0.641 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 19, 'max_features': 55, 'n_estimators': 225, 'random_state': 42}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "Accuracy: 0.6019\n",
      "\n",
      "AUC: 0.6292\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "print(\"Accuracy: %.4f\" % acc)\n",
    "print()\n",
    "\n",
    "probs = clf.predict_proba(X_test)\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'n_estimators': [10, 100],\n",
    "                     'max_depth' : [4, 5, 6],\n",
    "                     'min_samples_split': [2, 5, 10],\n",
    "                     'criterion':['mae'],\n",
    "                     'random_state':[42],\n",
    "                     'learning_rate': [0.03, 0.05], \n",
    "                    # 'subsample': [0.5, 1]\n",
    "                    }]\n",
    "clf = GridSearchCV(ensemble.GradientBoostingClassifier(), tuned_parameters, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()\n",
    "predictions = clf.predict(X_test)\n",
    "acc = roc_auc_score(y_test, predictions)\n",
    "print(\"accuracy_score: %.4f\" % acc)\n",
    "\n",
    "probs = clf.predict_proba(X_test)\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf', 'linear', 'poly'],\n",
    "                     'C': [1,10,20]}]\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=3)\n",
    "clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "acc = roc_auc_score(y_test, predictions)\n",
    "print(\"accuracy_score: %.4f\" % acc)\n",
    "\n",
    "probs = clf.predict_proba(X_test)\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'hidden_layer_sizes': [(1,),(50,50),(50,50,50),(50,50,50,50,50),(50,150,50,100,50)],\n",
    "                    'activation' : ['logistic', 'relu','tanh'],\n",
    "                    'learning_rate': ['constant', 'adaptive'],\n",
    "                    'alpha': [0.001,0.01,0.1],\n",
    "                    'random_state' : [42],\n",
    "                    'max_iter': [2000,1000],\n",
    "                    'solver': ['sgd','adam','lbfgs']}]\n",
    "clf = GridSearchCV(MLPClassifier(), tuned_parameters, cv=4)\n",
    "clf.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test2)))\n",
    "print()\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "acc = roc_auc_score(y_test, predictions)\n",
    "print(\"accuracy_score: %.4f\" % acc)\n",
    "\n",
    "probs = clf.predict_proba(X_test2)\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = clf.predict_proba(X_test2)\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)\n",
    "#false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test, clf.predict_proba(xtest)[:,1])\n",
    "#print(auc(false_positive_rate, true_positive_rate),roc_auc_score(Y_test, clf.predict_proba(xtest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
